{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Machine Learning Assignment 2</h1>\n",
    "<h2>Submitted by Skander Driss</h2>\n",
    "<h4>Professor Chase Kusterer<br>\n",
    "Hult International Business School</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skanderdriss/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.476758\n",
      "         Iterations 7\n",
      "Tuned Parameters  : {'criterion': 'gini', 'max_depth': 11, 'min_samples_leaf': 12, 'splitter': 'best'}\n",
      "Tuned Training AUC: 0.6448\n",
      "Training ACCURACY: 0.852\n",
      "Testing  ACCURACY: 0.8563\n",
      "AUC Score        : 0.8519\n"
     ]
    }
   ],
   "source": [
    "%timeit\n",
    "# importing libraries\n",
    "\n",
    "import pandas as pd                                  # data science essentials\n",
    "import random            as rand                     # random number gen\n",
    "import matplotlib.pyplot as plt                      # essential graphical output\n",
    "import seaborn as sns                                # enhanced graphical output\n",
    "from sklearn.model_selection import train_test_split # train-test split\n",
    "from sklearn.linear_model import LogisticRegression  # logistic regression\n",
    "from sklearn.metrics import confusion_matrix         # confusion matrix\n",
    "from sklearn.metrics import roc_auc_score            # auc score\n",
    "from sklearn.neighbors import KNeighborsClassifier   # KNN for classification\n",
    "from sklearn.neighbors import KNeighborsRegressor    # KNN for regression\n",
    "from sklearn.preprocessing import StandardScaler     # standard scaler\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import GridSearchCV     # hyperparameter tuning\n",
    "from sklearn.metrics import make_scorer              # customizable scorer\n",
    "from IPython.display import Image                    # displays on frontend\n",
    "import pydotplus\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "# interprets dot objects\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "\n",
    "# setting pandas print options\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "\n",
    "# specifying file name\n",
    "file = 'Apprentice_Chef_Dataset.xlsx'\n",
    "\n",
    "\n",
    "# reading the file into Python\n",
    "food = pd.read_excel(file)\n",
    "\n",
    "# Imputing the missing values: Family name missing will take the First name\n",
    "food['FAMILY_NAME'][food['FAMILY_NAME'].isnull()] = food['FIRST_NAME'][food['FAMILY_NAME'].isnull()]\n",
    "\n",
    "\n",
    "############################ Feature Engineering\n",
    "\n",
    "# Emails\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping over each email address\n",
    "for index, col in food.iterrows():\n",
    "    \n",
    "    # splitting email domain at '@'\n",
    "    split_email = food.loc[index, 'EMAIL'].split(sep = '@')\n",
    "    \n",
    "    # appending placeholder_lst with the results\n",
    "    placeholder_lst.append(split_email)\n",
    "    \n",
    "\n",
    "# converting placeholder_lst into a DataFrame \n",
    "email_df = pd.DataFrame(placeholder_lst)\n",
    "\n",
    "\n",
    "# STEP 2: concatenating with original DataFrame\n",
    "\n",
    "# renaming column to concatenate\n",
    "email_df.columns = ['name' ,'email_domain']\n",
    "\n",
    "\n",
    "# concatenating personal_email_domain with friends DataFrame\n",
    "food = pd.concat([food, email_df['email_domain']],\n",
    "                   axis = 1)\n",
    "\n",
    "\n",
    "# personal and junk email domain\n",
    "personal_email_domains = ['@gmail.com', '@yahoo.com','@protonmail.com']\n",
    "junk_email_domains=['@me.com','@aol.com' ,'@hotmail.com' ,'@live.com' ,'@msn.com' ,'@passport.com']\n",
    "\n",
    "# placeholder list\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping to group observations by domain type\n",
    "for domain in food['email_domain']:\n",
    "        if '@' + domain in personal_email_domains :\n",
    "            placeholder_lst.append('Personal_email')\n",
    "        elif '@' + domain in junk_email_domains :\n",
    "            placeholder_lst.append('Junk_email')\n",
    "        else:\n",
    "            placeholder_lst.append('Professional_email')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "food['domain_group'] = pd.Series(placeholder_lst )\n",
    "\n",
    "food['domain_group'].astype('category')\n",
    "\n",
    "#hot coding for domain (Professional/Personal)\n",
    "one_hot_domain = pd.get_dummies(food['domain_group'])\n",
    "food = food.join([one_hot_domain])\n",
    "\n",
    "\n",
    "############Prepation for Treshold\n",
    "\n",
    "unique_meals_change_hi         = 12.5\n",
    "CONTACTS_W_CUSTOMER_SERVICE_lo = 5\n",
    "CONTACTS_W_CUSTOMER_SERVICE_hi = 8\n",
    "cancellation_before_noon_hi    = 5\n",
    "cancellation_after_noon_hi     = 2\n",
    "pc_logins_lo                   = 4\n",
    "pc_logins_hi                   = 7\n",
    "MOBILE_LOGINS_lo               = 0\n",
    "MOBILE_LOGINS_hi               = 3\n",
    "MASTER_CLASSES_ATTENDED_hi     = 2\n",
    "AVG_CLICKS_PER_VISIT_lo        = 7\n",
    "\n",
    "cancellation_after_noon_change_at = 0 # zero inflated\n",
    "weekly_plan_change_at             = 0 # zero inflated\n",
    "total_photo_viewed_change_at      = 0 # zero inflated\n",
    "\n",
    "# UNIQUE_MEALS_PURCH\n",
    "food['change_unique_meals'] = 0\n",
    "condition = food.loc[0:,'change_unique_meals'][food['UNIQUE_MEALS_PURCH'] > unique_meals_change_hi]\n",
    "\n",
    "food['change_unique_meals'].replace(to_replace = condition,\n",
    "                                   value      = 1,\n",
    "                                   inplace    = True)\n",
    "\n",
    "# Contact with customer service\n",
    "food['out_CONTACTS_W_CUSTOMER_SERVICE'] = 0\n",
    "condition_hi = food.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][food['CONTACTS_W_CUSTOMER_SERVICE'] >= CONTACTS_W_CUSTOMER_SERVICE_hi]\n",
    "condition_lo = food.loc[0:,'out_CONTACTS_W_CUSTOMER_SERVICE'][food['CONTACTS_W_CUSTOMER_SERVICE'] <= CONTACTS_W_CUSTOMER_SERVICE_lo]\n",
    "\n",
    "food['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "food['out_CONTACTS_W_CUSTOMER_SERVICE'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "#cancellation_before_noon\n",
    "food['out_cancellation_before_noon'] = 0\n",
    "condition_hi = food.loc[0:,'out_cancellation_before_noon'][food['CANCELLATIONS_BEFORE_NOON'] > cancellation_before_noon_hi ]\n",
    "\n",
    "food['out_cancellation_before_noon'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "#cancellation_after_noon\n",
    "food['out_cancellation_after_noon'] = 0\n",
    "condition_hi = food.loc[0:,'out_cancellation_after_noon'][food['CANCELLATIONS_AFTER_NOON'] > cancellation_after_noon_hi ]\n",
    "\n",
    "food['out_cancellation_after_noon'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# Pc logins\n",
    "food['out_PC_LOGINS'] = 0\n",
    "condition_hi = food.loc[0:,'out_PC_LOGINS'][food['PC_LOGINS'] >= pc_logins_hi]\n",
    "condition_lo = food.loc[0:,'out_PC_LOGINS'][food['PC_LOGINS'] <= pc_logins_lo]\n",
    "\n",
    "food['out_PC_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "food['out_PC_LOGINS'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# mobile logins\n",
    "food['out_MOBILE_LOGINS'] = 0\n",
    "condition_hi = food.loc[0:,'out_MOBILE_LOGINS'][food['MOBILE_LOGINS'] >= MOBILE_LOGINS_hi ]\n",
    "condition_lo = food.loc[0:,'out_MOBILE_LOGINS'][food['MOBILE_LOGINS'] <= MOBILE_LOGINS_lo]\n",
    "food['out_MOBILE_LOGINS'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "food['out_MOBILE_LOGINS'].replace(to_replace = condition_lo,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "#MASTER_CLASSES_ATTENDED\n",
    "food['out_MASTER_CLASSES_ATTENDED'] = 0\n",
    "condition_hi = food.loc[0:,'out_MASTER_CLASSES_ATTENDED'][food['MASTER_CLASSES_ATTENDED'] >= MASTER_CLASSES_ATTENDED_hi]\n",
    "\n",
    "food['out_MASTER_CLASSES_ATTENDED'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "#avg click per visit\n",
    "food['out_AVG_CLICKS_PER_VISIT'] = 0\n",
    "condition_hi = food.loc[0:,'out_AVG_CLICKS_PER_VISIT'][food['AVG_CLICKS_PER_VISIT'] > AVG_CLICKS_PER_VISIT_lo]\n",
    "\n",
    "food['out_AVG_CLICKS_PER_VISIT'].replace(to_replace = condition_hi,\n",
    "                                    value      = 1,\n",
    "                                    inplace    = True)\n",
    "\n",
    "# CANCELLATIONS_AFTER_NOON\n",
    "food['change_cancellation_after_noon'] = 0\n",
    "condition = food.loc[0:,'change_cancellation_after_noon'][food['CANCELLATIONS_AFTER_NOON'] == cancellation_after_noon_change_at]\n",
    "\n",
    "food['change_cancellation_after_noon'].replace(to_replace = condition,\n",
    "                                       value      = 1,\n",
    "                                       inplace    = True)\n",
    "\n",
    "# WEEKLY_PLAN\n",
    "food['change_weekly_plan'] = 0\n",
    "condition = food.loc[0:,'change_weekly_plan'][food['WEEKLY_PLAN'] == weekly_plan_change_at]\n",
    "\n",
    "food['change_weekly_plan'].replace(to_replace = condition,\n",
    "                                       value      = 1,\n",
    "                                       inplace    = True)\n",
    "\n",
    "# Overall Cond\n",
    "food['change_total_photo_viewed'] = 0\n",
    "condition = food.loc[0:,'change_total_photo_viewed'][food['TOTAL_PHOTOS_VIEWED'] == total_photo_viewed_change_at]\n",
    "\n",
    "food['change_total_photo_viewed'].replace(to_replace = condition,\n",
    "                                       value      = 1,\n",
    "                                       inplace    = True)\n",
    "\n",
    "# placeholder list for PRODUCT_CATEGORIES_VIEWED\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping to group observations by category viewed\n",
    "for i in food['PRODUCT_CATEGORIES_VIEWED']:\n",
    "        if i == 1:\n",
    "            placeholder_lst.append('Categ_Viewed_1')\n",
    "        elif i == 2:\n",
    "            placeholder_lst.append('Categ_Viewed_2')\n",
    "        elif i == 3:\n",
    "            placeholder_lst.append('Categ_Viewed_3')\n",
    "        elif i == 4:\n",
    "            placeholder_lst.append('Categ_Viewed_4')\n",
    "        elif i == 5:\n",
    "            placeholder_lst.append('Categ_Viewed_5')\n",
    "        elif i == 6:\n",
    "            placeholder_lst.append('Categ_Viewed_6')\n",
    "        elif i == 7:\n",
    "            placeholder_lst.append('Categ_Viewed_7')\n",
    "        elif i == 8:\n",
    "            placeholder_lst.append('Categ_Viewed_8')\n",
    "        elif i == 9:\n",
    "            placeholder_lst.append('Categ_Viewed_9')\n",
    "        else:\n",
    "            placeholder_lst.append('Categ_Viewed_10')\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "food['categ_viewed'] = pd.Series(placeholder_lst )\n",
    "\n",
    "food['categ_viewed'].astype('category')\n",
    "\n",
    "#hot coding\n",
    "one_hot_categ_viewed = pd.get_dummies(food['categ_viewed'])\n",
    "food = food.join([one_hot_categ_viewed])\n",
    "\n",
    "\n",
    "# placeholder list for FOLLOWED_RECOMMENDATIONS_PCT\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping to group observations by Followed Recommendations\n",
    "for i in food['FOLLOWED_RECOMMENDATIONS_PCT']:\n",
    "        if i == 0:\n",
    "            placeholder_lst.append('Followed_rec_0')\n",
    "        elif i == 10:\n",
    "            placeholder_lst.append('Followed_rec_10')\n",
    "        elif i == 20:\n",
    "            placeholder_lst.append('Followed_rec_20')\n",
    "        elif i == 30:\n",
    "            placeholder_lst.append('Followed_rec_30')\n",
    "        elif i == 40:\n",
    "            placeholder_lst.append('Followed_rec_40')\n",
    "        elif i == 50:\n",
    "            placeholder_lst.append('Followed_rec_50')\n",
    "        elif i == 60:\n",
    "            placeholder_lst.append('Followed_rec_60')\n",
    "        elif i == 70:\n",
    "            placeholder_lst.append('Followed_rec_70')\n",
    "        elif i == 80:\n",
    "            placeholder_lst.append('Followed_rec_80')\n",
    "        else:\n",
    "            placeholder_lst.append('Followed_rec_90')\n",
    "\n",
    "\n",
    "# concatenating with original DataFrame\n",
    "food['Followed_rec'] = pd.Series(placeholder_lst )\n",
    "\n",
    "food['Followed_rec'].astype('category')\n",
    "\n",
    "#hot coding \n",
    "one_hot_Followed_rec = pd.get_dummies(food['Followed_rec'])\n",
    "food = food.join([one_hot_Followed_rec])\n",
    "\n",
    "\n",
    "# placeholder list for MEDIAN_MEAL_RATING\n",
    "placeholder_lst = []\n",
    "\n",
    "# looping to group observations by Rating\n",
    "for i in food['MEDIAN_MEAL_RATING']:\n",
    "        if i == 1:\n",
    "            placeholder_lst.append('1_star_rating')\n",
    "        elif i == 2:\n",
    "            placeholder_lst.append('2_star_rating')\n",
    "        elif i == 3:\n",
    "            placeholder_lst.append('3_star_rating')\n",
    "        elif i == 4:\n",
    "            placeholder_lst.append('4_star_rating')\n",
    "        elif i == 5:\n",
    "            placeholder_lst.append('5_star_rating')\n",
    "            \n",
    "# concatenating with original DataFrame\n",
    "food['Star_rating'] = pd.Series(placeholder_lst )\n",
    "\n",
    "food['Star_rating'].astype('category')\n",
    "\n",
    "#hot coding \n",
    "one_hot_Star_rating = pd.get_dummies(food['Star_rating'])\n",
    "food = food.join([one_hot_Star_rating])\n",
    "\n",
    "# declaring explanatory variables and dropping the invalid columns\n",
    "food_data = food.drop(['CROSS_SELL_SUCCESS',\n",
    "                      'NAME',\n",
    "                      'EMAIL', \n",
    "                      'FIRST_NAME', \n",
    "                      'FAMILY_NAME', \n",
    "                      'email_domain', \n",
    "                      'domain_group',\n",
    "                      'categ_viewed',\n",
    "                      'Followed_rec',\n",
    "                      'Star_rating'],\n",
    "                      axis = 1)\n",
    "\n",
    "\n",
    "# declaring response variable\n",
    "food_target = food.loc[ : , 'CROSS_SELL_SUCCESS']\n",
    "\n",
    "# train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "            food_data,\n",
    "            food_target,\n",
    "            test_size = 0.25,\n",
    "            random_state = 508,\n",
    "            stratify = food_target)\n",
    "\n",
    "\n",
    "# merging training data for statsmodels\n",
    "food_train = pd.concat([X_train, y_train], axis = 1)\n",
    "\n",
    "\n",
    "###check it\n",
    "# instantiating a logistic regression model object\n",
    "logistic_full = smf.logit(formula = \"\"\" CROSS_SELL_SUCCESS ~\n",
    "                                        MOBILE_NUMBER +\n",
    "                                        TASTES_AND_PREFERENCES +\n",
    "                                        FOLLOWED_RECOMMENDATIONS_PCT +\n",
    "                                        AVG_PREP_VID_TIME +\n",
    "                                        TOTAL_PHOTOS_VIEWED +\n",
    "                                        out_CONTACTS_W_CUSTOMER_SERVICE +\n",
    "                                        out_cancellation_before_noon +\n",
    "                                        change_cancellation_after_noon +\n",
    "                                        change_weekly_plan +\n",
    "                                        change_total_photo_viewed \"\"\",\n",
    "                                        data    = food_train)\n",
    "\n",
    "\n",
    "# fitting the model object\n",
    "results_full = logistic_full.fit()\n",
    "\n",
    "\n",
    "# checking the results SUMMARY\n",
    "results_full.summary()\n",
    "\n",
    "\n",
    "# declaring a hyperparameter space\n",
    "criterion_space = ['gini', 'entropy']\n",
    "splitter_space = ['best', 'random']\n",
    "depth_space = pd.np.arange(1, 25)\n",
    "leaf_space  = pd.np.arange(1, 100)\n",
    "\n",
    "\n",
    "# creating a hyperparameter grid\n",
    "param_grid = {'criterion'        : criterion_space,\n",
    "              'splitter'         : splitter_space,\n",
    "              'max_depth'        : depth_space,\n",
    "              'min_samples_leaf' : leaf_space}\n",
    "\n",
    "\n",
    "# INSTANTIATING the model object without hyperparameters\n",
    "tuned_tree = DecisionTreeClassifier(random_state = 802)\n",
    "\n",
    "\n",
    "# GridSearchCV object\n",
    "tuned_tree_cv = GridSearchCV(estimator  = tuned_tree,\n",
    "                             param_grid = param_grid,\n",
    "                             cv         = 3,\n",
    "                             scoring    = make_scorer(roc_auc_score,\n",
    "                                                      needs_threshold = False))\n",
    "\n",
    "\n",
    "# FITTING to the FULL DATASET (due to cross-validation)\n",
    "tuned_tree_cv.fit(food_data, food_target)\n",
    "\n",
    "\n",
    "# PREDICT step is not needed\n",
    "\n",
    "\n",
    "# printing the optimal parameters and best score\n",
    "print(\"Tuned Parameters  :\", tuned_tree_cv.best_params_)\n",
    "print(\"Tuned Training AUC:\", tuned_tree_cv.best_score_.round(4))\n",
    "\n",
    "# building a model based on hyperparameter tuning results\n",
    "\n",
    "# INSTANTIATING a logistic regression model with tuned values\n",
    "tree_tuned = tuned_tree_cv.best_estimator_\n",
    "\n",
    "\n",
    "# FIT step is not needed\n",
    "\n",
    "\n",
    "# PREDICTING based on the testing set\n",
    "tree_tuned_pred = tree_tuned.predict(X_test)\n",
    "\n",
    "\n",
    "# SCORING the results\n",
    "print('Training ACCURACY:', tree_tuned.score(X_train, y_train).round(4))\n",
    "print('Testing  ACCURACY:', tree_tuned.score(X_test, y_test).round(4))\n",
    "print('AUC Score        :', roc_auc_score(y_true  = y_test,\n",
    "                                          y_score = tree_tuned_pred).round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
